# Challenge Latam Devops

## Parte 1: Infraestructura e IaC

1. Para la infraestructura se utilizó principalmente servicios de AWS y estos se levantaron utilizando terraform con distintos modulos. Para la solución de este problema se propone utilizar como base de datos Redshift, pues precisamente esta se ecnuentra enfocada en el análisis de datos. Para tomar un enfoque pub/sub se propone utilizar el servicio de SNS de aws junto con lambda para desarrollar la API. Mas concretamente se desarrollaron 2 funciones lambda, una que funciona como API junto con API Gateway y que se encarga de recibir los GET solicitados por los usuarios, consultar a la BD y servir los datos solicitados, y la otra funciona como un suscriptor del topico de SNS en donde, al publicar un mensaje en el topico de SNS, esta función se encarga de procesar el mensaje y subir los datos a la base de datos de Redshift. La infraestructura de las funciones lambda junto con api-gateway y la asociación en la tabla de rutas se levantará automaticamente utilizando serverless, por ello sus modulos no se encuentran en terraform. En cuanto a la suscripción de la función lambda al topico, se asume que una vez creada la función lambda, manualmente se ingresa a SNS y se crea la suscripción con el arn de la función (esto se hace asi y no con terraform ya que es necesario tener el arn de la funcion lambda). Se aume que primero se ejecuta la creación de recursos de terraform y luego la creación de recursos con serverless.
2. Como se mencionó, gran parte de la infraestructura se levantó con terraform en varios modulos. Estos corresponden a los siguientes:
    - **main.tf**: Contiene la versión a utilizar de terraform y del proveedor de hashicorp/aws. Tambien define las llaves de aws a utilizar para poder levantar la infraesctrutura. Se asume que existe un bucket terraform-latam con el archivo terraform-state.tfstate el cual contiene los estados de los recursos de terraform. Adicionalmente se asume que existe un perfil creado "latam" con el cli de AWS que contiene las llaves con los permisos necesarios para levantar toda la infra.
    - **networking.tf**: Se creó una VPC de producción en us-east-1 con 3 subnets de app privada (que utilizará la aplicación) y 3 subnets de base de datos (que utilizará la BD). Cada subnet en la region us-east-1a, us-east-1b y us-east-1c para tener una mayor disponibilidad y en caso de que alguna región falle bastaría únicamente con cambiar la subnet y el servicio vuelve a estar disponible. Para este ejercicio se utilizará únicamente la subnet de us-east1a. Se crean tambien los grupos de seguridad db-ingress, el cual utilizará la applicacion para poder acceder a los recursos de la BD y se crea tambien el grupo de seguridad db-servers que permite el ingreso unicamente por el puerto 3306 desde los recursos que contengan unicamente el sg db-ingress. Esto entrega una mayo rcapa de protección a los datos, pues solo se permite el acceso desde db-ingress. Por ultimo se crea un sg "latam-challeng" que unicamente contiene una outbound rule que permite la salida hacia cualquier lado y que será utilizado por la función lambda.
    - **redshift.tf**: En este modulo se crea el cluster de redshift con las subnets de bds y con el sg de db-servers. Se tienen varias consideraciones en cuenta. La primera es que se asume que en el secrets manager de la cuenta existe un secreto "prod/redshift/credentials" con las credenciales a utilizar para el acceso al cluster. Se asume tambien que existe ya una llave KMS redshift que permite encriptar la base de datos y que existe un rol "AWSServiceRoleForRedshift" con la policy manejada por AWS "AmazonRedshiftServiceLinkedRolePolicy".
    - **sns.tf**: Se crea un topico en sns llamado "customers-topic"

## Parte 2: Aplicaciones y flujo CI/CD

Para este ejercicio se asume que existe una tabla clientes en la base de datos con los campos id, nombre, apellido, rut y correo. Tambien se asume que existe un secreto en el secrets manager de la cuenta con las credenciales y datos de conexión a la base de datos. Otra consideración a tener en cuenta es que se obviaron algunos permisos que deben incluirse en la función lambda, mas concretamente los permisos para poder leer del topico SNS. Por último, se crean custom domains para los endpoints de la api asumiendo que existe el certificado *.latam.com.

1. Para levantar la api HTTP se utilizó lambda junto con serverless. Se creó una función de lambda en python llamada get_client que simula una llamada a la base de datos para obtener un cliente especifico de la tabla clientes dado su id. Por lo tanto, esta función espera que en la llamada HTTP exista un query_param llamado client_id. Si no existe el parametro entonces entrega error 400. Si se entrega este parametro, se realiza la conexión a la base de datos y se ejecuta un select sobre la tabla clientes para obtener el cliente dado. En caso de que ocurra algun error, se responde con error 400 y se logea dentro de lambda el error. Al utilizarse serverless, este automaticamente levanta los endpoints indicados utilizando api gateway y se utiliza tambien una libreria de serverles para dejar los endpoints de la api como fijos utilizando custom domains, el cual crea los registros respectivos en route53.
2. Para el deploy mediante un flujo CI/CD se optó por utilizar github actions con un workflow. Este workflow se gatilla al realizar push sobre la rama master (en este caso esta parte se encuentra comentada ya que no se hará realmente el deploy) y ejecuta un ```sls create custom_domain --stage prod``` primero, y luego ejecuta un```sls deploy --stage prod``` para levantar los nuevos cambios del respositorio a lambda.
3. Adicionalmente a la función API de lambda, se creó una segunda función suscriber que se encarga de consumir el topico de SNS creado por terraform e insertar los datos del mensaje sobre la base de datos. Como bien se mencionó en la primera parte, la suscripción al topico SNS creado por terraform debe hacerse de manera manual pues el arn de la función no existe hasta que se ejcuta el script de serverless y este script debe ejecutarse luego de terraform. Para hacer esto se puede ejecutar el siguiente comando :
    ```
    aws sns subscribe --protocol lambda \
    --region us-east-1 \
    --topic-arn <arn del topico> \
    --notification-endpoint <arn de función lambda> \
    ```
4. Cuando un usuario quiere obtener los datos de un cliente llama al endpoint de la función hacia api gateway con /getClient. Api gateway realiza la llamada a lambda api y esta corre la query sobre redshift para obtner los datos del cliente y los retorna. En paralelo se tiene el servicio de suscripción de lambda que se encuentra suscrito al topico de SNS y cuando un mensaje es publicado, la función es encargada de insertarlo sobre la base de datos:

    ![Alt text](image.png)

## Parte 3: Pruebas de integración y Puntos Críticos de Calidad

Con el fin de realizar pruebas, se asume que existe un cliente en la base de datos que es de testing y tiene id 1.

1. Para agregar un flujo de testing al flujo ya existente de CI/CD se optó por levantar un servicio de test temporal igual al de producción y ejecutar las llamadas a la api hacia este servicio de prueba. Si todas las llamadas se realizan correctamente entonces se elimina este servicio de test temporal (en caso de que falle tambien se elimina el servicio temporal de testing) y se hace un deploy del servicio de producción. Para lograr esto, se agregan 2 stages al script de serverless, un stage "prod" y otro stage "test". El stage de prod se levanta con dominio customdomain.latam.com y el stage de test se levanta con dominio customdomain-test.latam.com. Ambos servicio levantan exactamente la misma funcion con los mismos grupos de seguridad y subnets para simular la prueba lo mas cercano a producción. Entonces, en el workflow de github actions primero se hace un deploy del stage test, se corren las pruebas (en este caso como la prueba era unicamente de un solo endpoint, se le pega al endpoint con curl y se espera 200, pero si la aplicación crece, se recomienda crear un script encargado de realizar las pruebas mas precisas como verificar que efectivamente las respuesta tiene la estructura que se espera) y si las pruebas se ejecutan con éxito, entonces se realiza un deploy del servicio de producción. Independientemente del resultado de las pruebas, el servicio de test siempre se elimina al final del workflow.
Existen varias razones por las que se escogió realizar el testing de esta forma. La primera, como bien se mencionó, al levantar prácticamente un clon de la aplicación, se tiene un servicio lo mas cercano a producción y lo mas cercano a la realidad. Por otra parte, dado que la base de datos se encuentra en una subnet privada solo accesible por las aplicaicones que utilicen el grupo de seguridad, si se corren pruebas desde el workflow directamente, este no podría llegar a la base de datos y entregaría timeout. Para solucionar esto se puede setear una VPN en el workflow y permitir el acceso a la base de datos desde una VPN tambien (crear un segundo grupo de seguridad vpn-ingress). Si se realiza eso se peuden correr pruebas hacia la base de datos sin necesidad de levantar un servicio clon. Esto nos lleva a las desventajas de realizar pruebas de esta forma, pues, al levantar un clon similar a la aplicación original, se duplica el tiempo del deploy, pues se debe primero esperar a que la aplicación de testing se encuentre lista, correr las pruebas y luego recién se levanta la aplicación de producción. Dependiendo del tamaño del servicio, esta solución pude nos siempre ser viable.
2. Para realizar pruebas sobre la aplicación siempre es recomendable crear un ambiente de QA o Staging que simule producción y que contenga todos los servicios que nos interesa probar. Por lo tanto, agregaria un workflow mas a serverless, similar al de test, pero que levante el servicio en un stage de QA y que utilice una base de datos de QA, no la de producción, pues en caso de que ocurra algún error, todas las pruebas se realizan sobre un ambiente controlado y separado al de producción de tal forma que no se ve afectado la operación cotidiana. Una vez creado el ambiente QA, se proponoe probar primero los endpoints y que la respuestas coincidan con lo esperado, por lo menos en estructura, por ejemplo si al hacer un get_client se espera recibir una respuesta con estado 200 y con el cliente, se debe verificar que esto ocurra. Tambien se debe probar los casos en que la aplicación o la base de datos no funcione correctamente y que las respuestas entregadas por la aplicación en estos casos no sean 200 o no tengan una estructura bien definida. El sistema debe ser capaz de manejar estos casos y no caerse por completo, si no entregar un mensaje de error de conexión o similar.Para esto se deben simular escenarios de fallo, como la pérdida de conexión con la base de datos y verificar que el sistema pueda recuperarse correctamente. Otra prueba que propongo hacer es una prueba de carga utilizando alguna herramienta como Jmeter, que permita realizar varias solicitudes simultaneas a la API para verificar que tanto la API como al BD pueden manejar todas estas conexiones en un caso de mucha demanda. En estos casos se debe medir tambien los tiempos de respuesta para verificar como se ve afectado todo el sistema en caso de una carga intensiva.
3. El primer punto crítico del sistema es la conexión a la base de datos. Si no se definen bien los recursos a utilizar por la base de datos, cuando haya un gran volumen de solicitudes puede que la cpu y memoria de la BD no sean suficientes y esta termine reiniciandose. En este tiempo se encolan las conexiones, las cuales, ingresan todas en simultaneo apenas vuelve a estar disponible la BD. Si el numero de conexiones encoladas es mayor a la capacidad que tiene la base de datos entonces no se permitirán mas conexiones y la aplicación seguramente se caiga por no poder acceder a la BD. Para resolver este problema momentaneamente se debe aumentar el número de instancias de la base de datos para que soporte mas conexiones y distribuya la carga. Si se quiere evitar que ocurra esto es necesario generar pruebas de carga utilizando herramientas como Jmeter o BlazeMeter y tener un margen de al menos un 20% de uso de CPU y memoria (es decir, que la CPU/Memoria no superen el 80%). Tambien es recomendable crear alarmas de CPU/Memoria/Conexiones que avisen de antemano que esto puede ocurrir y antes de que ocurra aumentar el número de instancias. Este corresponde a uno de los puntos criticos con respecto a la BD, pero tambien puede ocurrir con la API, si bien Lambda escala de manera automatica por defecto y soporta bastante concurrencia, tiene algunos parametros que se configuran de manera manual y no escalan automaticamente, como la memoria. Nuevamente, si hay un uso intensivo de la aplicación y no se define bien la cantidad de memoria, entonces se podria caer. La solución en este caso es la misma que ocurria con la base de datos, se deben correr pruebas de carga y medir como se comporta la memoria y si es necesario, aumentarla.
Hasta ahora solamente se discutieron puntos criticos con respecto a la performance del sistema, pero tambien puede ocurrir que el sistema no tenga problemas de performance por carga si no que haya un bug o error en el codigo. Puede ocurrir que las conexiones a la base de datos no se cierren correctamente, o que haya un bug que genere error en la aplicación porque algun dato tiene una estructra distinta, entre varios problemas que podrian ocurrir. En estos casos la aplicación puede fallar y no es necesariamente por carga. Para mitigar estos errores (es imposible evitar por completo bugs en aplicaciones grandes) se puede tener un sistema de logs y de alarmas que se gatillen cuando un error se repite varias veces. Existen varias herramientas para esto como AppOptics o en el mismo aws ElasticSearch. Estas herramientas permiten crear alarmas si existen muchos errores dentro de los logs o si hay un comportamiento anormal y por su puesto sirven tambien para visualizar estos errores y resolverlos lo antes posible.
Por ultimo, otro punto critico de la aplicación es su seguridad. Si no es necesario que un endpoint o acceso a la aplicacion deba ser publico, entonces se debe dejar privado. Por ejemplo la base de datos en la implementación de este problema se levantó sobre un subnet privada solamente accesible desde las aplicaciones y desde el puerto 3306. Tambien, en caso de ser necesario, se debe implementar un sistema seguro de autenticación de usuarios. Es posible tambien en AWS utilizar la herramienta de WAF (web application firewall) en donde se pueden definir reglas para evitar ataques de bots o intentos de ataques. Con estos puntos se peude robustecer enormemente la seguridad del servicio.
4. Como se fue mencionando a lo largo de la pregunta anterior, para robustecer el sistema es necesario correr pruebas tanto de estres, como de seguridad y de integración para verificar que todo funcione correctamente y que se están asignando los recursos necesarios. De todas formas, es imposible saber como se comportará el sistema en un futuro y el flujo que tendrá, asi como tambien es imposible evitar bugs y errores en aplicaciones grandes. Si bien AWS ofrece politicas de autoescalamiento para mitigar estos problemas, estas no cubren todos los casos y no siempre son suficientes. Es por ello que es necesario crear un sistema de logs y de alarmas que permitan saber de antemano cuando un error ocurrirá. Alarmas de CPU, Memoria, Conexiones, Errores, entre otras, que se gatillen cuando aumentan inusualmente pueden ser muy utiles para asignar manualmente recursos al sistema en casos de mucha carga o resolver un problema antes de que escale mucho y evitar que un error se convierta en una caida.

## Parte 4: Métricas y Monitoreo

1. Entre las metricas que se pueden tener para medir la salud y rendimiento del sistema se encuentran las siguientes:
    - Número de Requests: El número de request nos puede dar una idea de que tanto esta siendo solicitada la aplicación. Si existe un gran uso de CPU/Memoria y un gran numero de request, es lo normal pues significa que el sistema esta siendo utilizado con una gran carga, pero si hay un gran uso de CPU/Memoria y un bajo numero de requests, entonces puede que exista algun error en el codigo que esta utilizando mas recursos de lo necesario o la cantidad de CPU asingada no es suficiente.
    - Conexiones a BD: AWS permite medir la cantidad de conexiones a la BD lo que resulta útil para notar cuando existen errores en el codigo y las conexiones no son cerradas. Si una base de datos llega a su limite de conexiones entonces no permite el ingreso de conexiones nuevas evitando que la aplicación pueda conectarse y generando una potencial caida. Mantener un numero bajo de conexiones es crucial para evitar problemas.
    - Error Count Rate: Lambda ofrece una metríca para contar la cantidad de eventos que fallan con respecto al total de eventos. Si esta métrica aumenta mucho es preocupante pues significa que de todas las request, varias tienen algún error.
2. 