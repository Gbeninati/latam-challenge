# Challenge Latam Devops

## Parte 1: Infraestructura e IaC

1. Para la infraestructura se utilizó principalmente servicios de AWS y estos se levantaron utilizando terraform con distintos modulos. Para la solución de este problema se propone utilizar como base de datos Redshift, pues precisamente esta se ecnuentra enfocada en el análisis de datos. Para tomar un enfoque pub/sub se propone utilizar el servicio de SNS de aws junto con lambda para desarrollar la API. Mas concretamente se desarrollaron 2 funciones lambda, una que funciona como API junto con API Gateway y que se encarga de recibir los GET solicitados por los usuarios, consultar a la BD y servir los datos solicitados, y la otra funciona como un suscriptor del topico de SNS en donde, al publicar un mensaje en el topico de SNS, esta función se encarga de procesar el mensaje y subir los datos a la base de datos de Redshift. La infraestructura de las funciones lambda junto con api-gateway y la asociación en la tabla de rutas se levantará automaticamente utilizando serverless, por ello sus modulos no se encuentran en terraform. En cuanto a la suscripción de la función lambda al topico, se asume que una vez creada la función lambda, manualmente se ingresa a SNS y se crea la suscripción con el arn de la función (esto se hace asi y no con terraform ya que es necesario tener el arn de la funcion lambda). Se aume que primero se ejecuta la creación de recursos de terraform y luego la creación de recursos con serverless.
2. Como se mencionó, gran parte de la infraestructura se levantó con terraform en varios modulos. Estos corresponden a los siguientes:
    - **main.tf**: Contiene la versión a utilizar de terraform y del proveedor de hashicorp/aws. Tambien define las llaves de aws a utilizar para poder levantar la infraesctrutura. Se asume que existe un bucket terraform-latam con el archivo terraform-state.tfstate el cual contiene los estados de los recursos de terraform. Adicionalmente se asume que existe un perfil creado "latam" con el cli de AWS que contiene las llaves con los permisos necesarios para levantar toda la infra.
    - **networking.tf**: Se creó una VPC de producción en us-east-1 con 3 subnets de app privada (que utilizará la aplicación) y 3 subnets de base de datos (que utilizará la BD). Cada subnet en la region us-east-1a, us-east-1b y us-east-1c para tener una mayor disponibilidad y en caso de que alguna región falle bastaría únicamente con cambiar la subnet y el servicio vuelve a estar disponible. Para este ejercicio se utilizará únicamente la subnet de us-east1a. Se crean tambien los grupos de seguridad db-ingress, el cual utilizará la applicacion para poder acceder a los recursos de la BD y se crea tambien el grupo de seguridad db-servers que permite el ingreso unicamente por el puerto 3306 desde los recursos que contengan unicamente el sg db-ingress. Esto entrega una mayo rcapa de protección a los datos, pues solo se permite el acceso desde db-ingress. Por ultimo se crea un sg "latam-challeng" que unicamente contiene una outbound rule que permite la salida hacia cualquier lado y que será utilizado por la función lambda.
    - **redshift.tf**: En este modulo se crea el cluster de redshift con las subnets de bds y con el sg de db-servers. Se tienen varias consideraciones en cuenta. La primera es que se asume que en el secrets manager de la cuenta existe un secreto "prod/redshift/credentials" con las credenciales a utilizar para el acceso al cluster. Se asume tambien que existe ya una llave KMS redshift que permite encriptar la base de datos y que existe un rol "AWSServiceRoleForRedshift" con la policy manejada por AWS "AmazonRedshiftServiceLinkedRolePolicy".
    - **sns.tf**: Se crea un topico en sns llamado "customers-topic"

## Parte 2: Aplicaciones y flujo CI/CD

Para este ejercicio se asume que existe una tabla clientes en la base de datos con los campos id, nombre, apellido, rut y correo. Tambien se asume que existe un secreto en el secrets manager de la cuenta con las credenciales y datos de conexión a la base de datos. Otra consideración a tener en cuenta es que se obviaron algunos permisos que deben incluirse en la función lambda, mas concretamente los permisos para poder leer del topico SNS. Por último, se crean custom domains para los endpoints de la api asumiendo que existe el certificado *.latam.com.

1. Para levantar la api HTTP se utilizó lambda junto con serverless. Se creó una función de lambda en python llamada get_client que simula una llamada a la base de datos para obtener un cliente especifico de la tabla clientes dado su id. Por lo tanto, esta función espera que en la llamada HTTP exista un query_param llamado client_id. Si no existe el parametro entonces entrega error 400. Si se entrega este parametro, se realiza la conexión a la base de datos y se ejecuta un select sobre la tabla clientes para obtener el cliente dado. En caso de que ocurra algun error, se responde con error 400 y se logea dentro de lambda el error. Al utilizarse serverless, este automaticamente levanta los endpoints indicados utilizando api gateway y se utiliza tambien una libreria de serverles para dejar los endpoints de la api como fijos utilizando custom domains, el cual crea los registros respectivos en route53.
2. Para el deploy mediante un flujo CI/CD se optó por utilizar github actions con un workflow. Este workflow se gatilla al realizar push sobre la rama master y ejecuta un ```sls create custom_domain --stage prod``` primero, y luego ejecuta un```sls deploy --stage prod``` para levantar los nuevos cambios del respositorio a lambda.
3. Adicionalmente a la función API de lambda, se creó una segunda función suscriber que se encarga de consumir el topico de SNS creado por terraform e insertar los datos del mensaje sobre la base de datos. Como bien se mencionó en la primera parte, la suscripción al topico SNS creado por terraform debe hacerse de manera manual pues el arn de la función no existe hasta que se ejcuta el script de serverless y este script debe ejecutarse luego de terraform. Para hacer esto se puede ejecutar el siguiente comando :
    ```
    aws sns subscribe --protocol lambda \
    --region us-east-1 \
    --topic-arn <arn del topico> \
    --notification-endpoint <arn de función lambda> \
    ```
4. Cuando un usuario quiere obtener los datos de un cliente llama al endpoint de la función hacia api gateway con /getClient. Api gateway realiza la llamada a lambda api y esta corre la query sobre redshift para obtner los datos del cliente y los retorna. En paralelo se tiene el servicio de suscripción de lambda que se encuentra suscrito al topico de SNS y cuando un mensaje es publicado, la función es encargada de insertarlo sobre la base de datos:

    ![Alt text](image.png)

### Parte 3: Pruebas de integración y Puntos Críticos de Calidad

1. 